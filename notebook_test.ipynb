{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестовое задание для проекта «Parler-TTS для русского языка»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План оценки модели\n",
    "\n",
    "Нужно выбрать тексты, которые позволят оценить основные характеристики синтеза речи. Проверить синтез эмоционально окрашенных фраз, чисел, дат и акронимов, чтобы оценить способность модели корректно обрабатывать эти элементы.\n",
    "\n",
    "Можно сравнить ... (декомпозирование понятия \"оценка синтеза речи\")\n",
    "- Насколько голос звучит естественно (не как робот)\n",
    "- Правильное использование интонации для разных типов предложений\n",
    "- Чёткость и корректность произнесения звуков\n",
    "- Пол и высота звука говорящего\n",
    "- Насколько синтезированный звук соответствует входному тексту\n",
    "- Передача эмоций в голосе\n",
    "- Скорость говорения\n",
    "\n",
    "Обозначу особенности датасета и тестируемой модели.\n",
    "Датасет содержит аудиозаписи только женского голоса и на английском языке, поэтому исключаем некоторые вышеперечисленные критерии оценки.\n",
    "Остаются критерии:\n",
    "- Насколько голос звучит естественно\n",
    "- Чёткость и корректность произнесения звуков\n",
    "- Насколько синтезированный звук соответствует входному тексту\n",
    "- Передача эмоций в голосе\n",
    "- Сходство с целевым голосом Jenny\n",
    "\n",
    "Для тестирования использовались данные https://huggingface.co/datasets/ylacombe/jenny-tts-6h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор метрик для оценки качества\n",
    "- PESQ (Perceptual Evaluation of Speech Quality)\n",
    "- Mel Cepstral Distortion (MCD)\n",
    "- Signal-to-noise ratio (SNR)\n",
    "- WER (Word Error Rate)\n",
    "Далее будет краткое сравнение метрик\n",
    "\n",
    "Получить субъективную оценку слушателя (то есть меня :)) и провести сравнение между синтезированным и эталонным аудио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему эти метрики?\n",
    "\n",
    "1. PESQ\n",
    "- Измеряет восприятие качества речи на слух, сравнивая синтезированное аудио с эталонным. Хорошо отражает воспринимаемую \"чистоту\" речи, наличие шумов и артефактов.\n",
    "Ограничение - ориентирована больше на технические искажения, чем на естественность или эмоциональность.\n",
    "\n",
    "2. Mel\n",
    "- Измеряет расстояние между спектрограммами эталонного и синтезированного звука. Хорошо подходит для технической оценки соответствия тембра и артикуляции. Чувствительна к деталям синтеза (например, мелодия, тембр, частотные характеристики). Это сугубо техническая метрика.\n",
    "\n",
    "3. SNR\n",
    "- В контексте TTS SNR измеряет процент нежелательного шума в аудиопотоке относительно распознаваемой речи. Это влияет на способность слышать и понимать речь при наличии фонового шума.\n",
    "\n",
    "4. WER\n",
    "- Измеряет расхождения между текстом, распознанным из синтезированной речи, и исходным текстом. Простой способ проверить, насколько результат понятен ASR-системам.\n",
    "\n",
    "На данный момент нет универсальной метрики, которая могла бы заменить все перечисленные. Поэтому следует провести сравнение по всем.\n",
    "Информация взята с Torch Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация аудио с помощью модели\n",
    "\n",
    "Промпт был сгенерирован с помощью ChatGPT следующим образом:\n",
    "\"Ты - известный писатель на английском языке. Напиши небольшой отрывок прозаического текста с обязательным использованием вопросительного предложения, восклицательного предложения, многоточия, число и дата от лица женщины.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:parler_tts.modeling_parler_tts:Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the audio_encoder: <class 'parler_tts.dac_wrapper.modeling_dac.DACModel'> is overwritten by shared audio_encoder config: DACConfig {\n",
      "  \"_name_or_path\": \"ylacombe/dac_44khZ_8kbps\",\n",
      "  \"architectures\": [\n",
      "    \"DACModel\"\n",
      "  ],\n",
      "  \"codebook_size\": 1024,\n",
      "  \"frame_rate\": 86,\n",
      "  \"latent_dim\": 1024,\n",
      "  \"model_bitrate\": 8,\n",
      "  \"model_type\": \"dac_on_the_hub\",\n",
      "  \"num_codebooks\": 9,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/decoder_400M/\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"StableSpeechForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": false,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-jenny-30H\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-jenny-30H\")\n",
    "# Проверим, сможет ли прочитать числительные в таком формате.\n",
    "prompt = \"April 14th, 2025. It was almost 8:00 PM, and the room felt heavier than usual. My mind replayed his words: “Sometimes, love isn’t enough.” How cruel! How could he write that and still expect me to understand? Outside, a car horn shattered the stillness, followed by an impatient shout.\"\n",
    "description = \"Jenny speaks at an average pace with an animated delivery in a very confined sounding environment with clear audio quality.\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# Создание директории для сохранения результатов\n",
    "output_dir = \"generated_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "\n",
    "output_path = os.path.join(output_dir, \"parler_tts_out_01.wav\")\n",
    "sf.write(output_path, audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:parler_tts.modeling_parler_tts:Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the audio_encoder: <class 'parler_tts.dac_wrapper.modeling_dac.DACModel'> is overwritten by shared audio_encoder config: DACConfig {\n",
      "  \"_name_or_path\": \"ylacombe/dac_44khZ_8kbps\",\n",
      "  \"architectures\": [\n",
      "    \"DACModel\"\n",
      "  ],\n",
      "  \"codebook_size\": 1024,\n",
      "  \"frame_rate\": 86,\n",
      "  \"latent_dim\": 1024,\n",
      "  \"model_bitrate\": 8,\n",
      "  \"model_type\": \"dac_on_the_hub\",\n",
      "  \"num_codebooks\": 9,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/decoder_400M/\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"StableSpeechForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": false,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-jenny-30H\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-jenny-30H\")\n",
    "\n",
    "prompt = \"April fourteenth twenty twenty five. It was almost eight PM, and the room felt heavier than usual. My mind replayed his words: “Sometimes, love isn’t enough.” How cruel! How could he write that and still expect me to understand? Outside, a car horn shattered the stillness, followed by an impatient shout.\"\n",
    "\n",
    "# Создание директории для сохранения результатов\n",
    "output_dir = \"generated_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "\n",
    "output_path = os.path.join(output_dir, \"parler_tts_out_02.wav\")\n",
    "sf.write(output_path, audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наблюдения после генерации\n",
    "\n",
    "По наблюдениям, при первой генерации аудиоролик не содержал произношения даты и времени. Однако, все знаки препинания интонационно соблюдены, что очень даже неплохо. Там, где стоит многоточие, чувствуется длинная пауза. Произношение слов чёткое и корректное, голос максимально похож на оригинальный Jenny.\n",
    "Вторая генерация, когда все числительные были переписаны словами, дала более качественный результат, потому что все слова были произнесены.\n",
    "Сильной роботизации не чувствуется в голосе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка синтеза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cpu\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the audio_encoder: <class 'parler_tts.dac_wrapper.modeling_dac.DACModel'> is overwritten by shared audio_encoder config: DACConfig {\n",
      "  \"_name_or_path\": \"ylacombe/dac_44khZ_8kbps\",\n",
      "  \"architectures\": [\n",
      "    \"DACModel\"\n",
      "  ],\n",
      "  \"codebook_size\": 1024,\n",
      "  \"frame_rate\": 86,\n",
      "  \"latent_dim\": 1024,\n",
      "  \"model_bitrate\": 8,\n",
      "  \"model_type\": \"dac_on_the_hub\",\n",
      "  \"num_codebooks\": 9,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "WARNING:parler_tts.modeling_parler_tts:Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/decoder_400M/\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"StableSpeechForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": false,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n",
      "INFO:__main__:Processing 10 samples\n",
      "Processing samples:  10%|█         | 1/10 [00:25<03:52, 25.79s/it]INFO:__main__:Processed 2 samples. Current averages - SNR: -2.2475 dB, WER: 0.1190\n",
      "Processing samples:  30%|███       | 3/10 [01:10<02:29, 21.38s/it]INFO:__main__:Processed 4 samples. Current averages - SNR: -2.5706 dB, WER: 0.1845\n",
      "Processing samples:  50%|█████     | 5/10 [02:42<02:59, 35.86s/it]INFO:__main__:Processed 6 samples. Current averages - SNR: -2.7067 dB, WER: 0.1635\n",
      "Processing samples:  70%|███████   | 7/10 [04:01<01:56, 38.81s/it]INFO:__main__:Processed 8 samples. Current averages - SNR: -2.7777 dB, WER: 0.1563\n",
      "Processing samples:  90%|█████████ | 9/10 [05:35<00:42, 42.17s/it]INFO:__main__:Processed 10 samples. Current averages - SNR: -2.8605 dB, WER: 0.1340\n",
      "Processing samples: 100%|██████████| 10/10 [06:33<00:00, 39.31s/it]\n",
      "INFO:__main__:Финальные метрики качества:\n",
      "INFO:__main__:SNR: -2.8605\n",
      "INFO:__main__:WER: 0.1340\n",
      "INFO:__main__:processed_samples: 10\n",
      "INFO:__main__:failed_samples: 0\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import librosa\n",
    "from jiwer import wer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Логирование\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    \"\"\"Загрузка модели и токенизатора с обработкой ошибок.\"\"\"\n",
    "    try:\n",
    "        model = ParlerTTSForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model and tokenizer: {e}\")\n",
    "        raise\n",
    "\n",
    "def calculate_snr(reference, synthesized, sr):\n",
    "    \"\"\"\n",
    "    Расчет отношения сигнал/шум (SNR) между эталонным и синтезированным аудио.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        min_length = min(len(reference), len(synthesized))\n",
    "        reference = reference[:min_length]\n",
    "        synthesized = synthesized[:min_length]\n",
    "        \n",
    "        signal_power = np.mean(reference ** 2)\n",
    "        \n",
    "        noise = reference - synthesized\n",
    "        noise_power = np.mean(noise ** 2)\n",
    "        \n",
    "        if noise_power == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        snr = 10 * np.log10(signal_power / noise_power)\n",
    "        return snr\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error computing SNR: {e}\")\n",
    "        return float('-inf')\n",
    "\n",
    "def generate_audio_and_text(model, tokenizer, description, text):\n",
    "    try:\n",
    "        # Токенизация описания и текста\n",
    "        tokens_description = tokenizer(\n",
    "            description,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        tokens_text = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # Перемещение тензоров на нужное устройство\n",
    "        input_ids = tokens_description.input_ids.to(device)\n",
    "        prompt_input_ids = tokens_text.input_ids.to(device)\n",
    "        \n",
    "        # Генерация аудио\n",
    "        with torch.no_grad():\n",
    "            generation = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                prompt_input_ids=prompt_input_ids,\n",
    "                max_length=1000\n",
    "            )\n",
    "            \n",
    "            # Генерация текста (используем те же входные данные)\n",
    "            text_output = tokenizer.batch_decode(prompt_input_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        return generation.cpu().numpy().squeeze(), text_output\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generation: {e}\")\n",
    "        raise\n",
    "\n",
    "def evaluate_metrics(dataset, model, tokenizer, num_samples=10):  # Изменено на 10 сэмплов, изначально стояли все\n",
    "    snr_scores = []\n",
    "    wer_scores = []\n",
    "    failed_samples = 0\n",
    "    \n",
    "    total_samples = min(num_samples, len(dataset))\n",
    "    logger.info(f\"Processing {total_samples} samples\")\n",
    "    \n",
    "    default_description = \"Jenny speaks at an average pace with an animated delivery in a very confined sounding environment with clear audio quality.\"\n",
    "\n",
    "    for idx in tqdm(range(total_samples), desc=\"Processing samples\"):\n",
    "        try:\n",
    "            sample = dataset[idx]\n",
    "\n",
    "            required_keys = [\"transcription\", \"audio\", \"transcription_normalised\"]\n",
    "            if not all(key in sample for key in required_keys):\n",
    "                logger.warning(f\"Sample {idx} missing required keys\")\n",
    "                failed_samples += 1\n",
    "                continue\n",
    "\n",
    "            # Нужен текстовый промпт и аудиофайл\n",
    "            prompt = sample[\"transcription\"]\n",
    "            audio_info = sample[\"audio\"]\n",
    "            ref_audio = audio_info[\"array\"]\n",
    "            sr = audio_info[\"sampling_rate\"]\n",
    "\n",
    "            # Проверка валидности аудио\n",
    "            if len(ref_audio) == 0:\n",
    "                logger.warning(f\"Empty reference audio in sample {idx}\")\n",
    "                failed_samples += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                gen_audio, gen_text = generate_audio_and_text(model, tokenizer, default_description, prompt)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to generate audio/text for sample {idx}: {e}\")\n",
    "                failed_samples += 1\n",
    "                continue\n",
    "\n",
    "            # Преобразование эталонного аудио к нужной частоте дискретизации для метрики\n",
    "            if sr != model.config.sampling_rate:\n",
    "                ref_audio = librosa.resample(ref_audio, orig_sr=sr, target_sr=model.config.sampling_rate)\n",
    "\n",
    "            snr = calculate_snr(ref_audio, gen_audio, model.config.sampling_rate)\n",
    "            if snr != float('-inf'):\n",
    "                snr_scores.append(snr)\n",
    "\n",
    "            ref_text = sample[\"transcription_normalised\"]\n",
    "            try:\n",
    "                wer_score = wer(ref_text, gen_text)\n",
    "                wer_scores.append(wer_score)\n",
    "                logger.debug(f\"Sample {idx} - Reference: '{ref_text}', Generated: '{gen_text}'\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error calculating WER for sample {idx}: {e}\")\n",
    "\n",
    "            # Логирование промежуточных результатов\n",
    "            if (idx + 1) % 2 == 0 and snr_scores and wer_scores:  # Каждые 2 сэмпла\n",
    "                logger.info(f\"Processed {idx + 1} samples. Current averages - SNR: {np.mean(snr_scores):.4f} dB, WER: {np.mean(wer_scores):.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample {idx}: {e}\")\n",
    "            failed_samples += 1\n",
    "            continue\n",
    "\n",
    "    if not snr_scores and not wer_scores:\n",
    "        raise ValueError(\"No valid metrics were computed\")\n",
    "    \n",
    "    results = {}\n",
    "    if snr_scores:\n",
    "        results[\"SNR\"] = np.mean(snr_scores)\n",
    "    if wer_scores:\n",
    "        results[\"WER\"] = np.mean(wer_scores)\n",
    "    \n",
    "    results.update({\n",
    "        \"processed_samples\": total_samples - failed_samples,\n",
    "        \"failed_samples\": failed_samples\n",
    "    })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        model_name = \"parler-tts/parler-tts-mini-jenny-30H\"\n",
    "        model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "\n",
    "        # Загрузка датасета jenny-tts-6h\n",
    "        dataset = load_dataset(\"ylacombe/jenny-tts-6h\", split=\"train\")\n",
    "\n",
    "        metrics = evaluate_metrics(dataset, model, tokenizer)\n",
    "        \n",
    "        logger.info(\"Финальные метрики качества:\")\n",
    "        for metric, value in metrics.items():\n",
    "            logger.info(f\"{metric}: {value:.4f}\" if isinstance(value, float) else f\"{metric}: {value}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание полученных результатов\n",
    "\n",
    "По итогам тестирования (к сожалению, на 10 записях иначе не успело бы выполниться до дедлайна) были получены значения двух метрик:\n",
    "\n",
    "|**SNR**   |**WER**   |\n",
    "|----------|----------|\n",
    "|-2,8605   |0,1340    |\n",
    "\n",
    "Они являются вполне нормальными для данной модели, учитывая особенности тренировочного датасета.\n",
    "Было бы, конечно, гораздо интереснее тестировать модель, которая обучалась на фразах разных дикторов (разного пола, акцента...)\n",
    "\n",
    "Оценивая субъективные метрики, можно сказать, что текст генерируется довольно четко, хорошо воспринимается человечиским слухом, учитываются паузы и эмоциональная окраска речи на вполне достойном уровне, голос не кажется роботизированным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Небольшой комментарий\n",
    "При попытке учесть метрику PESQ возникли проблемы с установкой библиотеки на Windows...поэтому она не была учтена в работе\n",
    "Не хватило времени разобраться глубже в проблеме и задаче, но тестировать очень понравилось :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
