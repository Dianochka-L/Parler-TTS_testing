# Parler-TTS_testing
Оценка модели parler-tts-mini-jenny-30H
---
В данном проекте производится оценка качества работы дообученной модели  Parler-TTS на датасете Jenny.
Для тестирования использовались данные https://huggingface.co/datasets/ylacombe/jenny-tts-6h

## План оценки модели

Нужно выбрать тексты, которые позволят оценить основные характеристики синтеза речи. Проверить синтез эмоционально окрашенных фраз, чисел, дат и акронимов, чтобы оценить способность модели корректно обрабатывать эти элементы.

Декомпозирование понятия "оценка синтеза речи":
- Насколько голос звучит естественно (не как робот)
- Правильное использование интонации для разных типов предложений
- Чёткость и корректность произнесения звуков
- Пол и высота звука говорящего
- Насколько синтезированный звук соответствует входному тексту
- Передача эмоций в голосе
- Скорость говорения

Обозначу особенности датасета и тестируемой модели.
Датасет содержит аудиозаписи только женского голоса и на английском языке, поэтому исключаем некоторые вышеперечисленные критерии оценки.
Остаются критерии:
- Насколько голос звучит естественно
- Чёткость и корректность произнесения звуков
- Насколько синтезированный звук соответствует входному тексту
- Передача эмоций в голосе
- Сходство с целевым голосом Jenny

## Выбор метрик для оценки качества
- PESQ (Perceptual Evaluation of Speech Quality)
- MCD (Mel Cepstral Distortion)
- SNR (Signal-to-noise ratio)
- WER (Word Error Rate)

**Получить субъективную оценку слушателя и провести сравнение между синтезированным и эталонным аудио.**

1. **PESQ**
Измеряет восприятие качества речи на слух, сравнивая синтезированное аудио с эталонным. Хорошо отражает воспринимаемую "чистоту" речи, наличие шумов и артефактов.
Ограничение - ориентирована больше на технические искажения, чем на естественность или эмоциональность.

2. **Mel**
Измеряет расстояние между спектрограммами эталонного и синтезированного звука. Хорошо подходит для технической оценки соответствия тембра и артикуляции. Чувствительна к деталям синтеза (например, мелодия, тембр, частотные характеристики). Это сугубо техническая метрика.

3. **SNR**
В контексте TTS SNR измеряет процент нежелательного шума в аудиопотоке относительно распознаваемой речи. Это влияет на способность слышать и понимать речь при наличии фонового шума.

4. **WER**
Измеряет расхождения между текстом, распознанным из синтезированной речи, и исходным текстом. Простой способ проверить, насколько результат понятен ASR-системам.

На данный момент нет универсальной метрики, которая могла бы заменить все перечисленные. Поэтому следует провести сравнение по всем.

## Инструкция для запуска
Для корректной работы следует выполнить в командной строке следующие шаги.
1. Установка среды

```bash
python -m venv venv
```

2. Активация среды

- На Windwos:

```bash
.venv\Scripts\Activate
```

- На MacOS/Linux

```bash
source .venv\bin\activate
```

3. Установка зависимостей

```bash
pip install -r requirements.txt
```

4. Открыть файл ноутбука .ipynb
5. Следовать инструкциям в ячейках markdown

## Описание полученных результатов

По итогам тестирования были получены значения двух метрик:

|**SNR**   |**WER**   |
|----------|----------|
|-2,8605   |0,1340    |

Они являются вполне нормальными для данной модели, учитывая особенности тренировочного датасета.
Было бы, конечно, гораздо интереснее тестировать модель, которая обучалась на фразах разных дикторов (разного пола, акцента...)

Оценивая субъективные метрики, можно сказать, что текст генерируется довольно четко, хорошо воспринимается человечиским слухом, учитываются паузы и эмоциональная окраска речи на вполне достойном уровне, голос не кажется роботизированным.
